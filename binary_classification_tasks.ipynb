{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5113f8e2",
   "metadata": {},
   "source": [
    "Task A: Binary Classification Using Handcrafted Features and ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f409d8-c20e-4417-84f1-7c4dffec9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Accuracy: 0.9201474201474201\n",
      "Best MLP Accuracy: 0.9004914004914005\n",
      "\n",
      "SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       386\n",
      "           1       0.90      0.96      0.93       428\n",
      "\n",
      "    accuracy                           0.92       814\n",
      "   macro avg       0.92      0.92      0.92       814\n",
      "weighted avg       0.92      0.92      0.92       814\n",
      "\n",
      "\n",
      "MLP Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89       386\n",
      "           1       0.90      0.91      0.91       428\n",
      "\n",
      "    accuracy                           0.90       814\n",
      "   macro avg       0.90      0.90      0.90       814\n",
      "weighted avg       0.90      0.90      0.90       814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def load_images(folder):\n",
    "    images, labels = [], []\n",
    "    for category in [\"with_mask\", \"without_mask\"]:\n",
    "        path = os.path.join(folder, category)\n",
    "        label = 1 if category == \"with_mask\" else 0\n",
    "        for file in os.listdir(path):\n",
    "            img_path = os.path.join(path, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (64, 64))\n",
    "                img = cv2.equalizeHist(img)  # Apply Histogram Equalization\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hog_feature = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        lbp_feature = local_binary_pattern(img, P=8, R=1, method='uniform').flatten()\n",
    "        canny_edges = cv2.Canny(img, 100, 200).flatten()\n",
    "        \n",
    "        # Sobel Edge Detection\n",
    "        sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3).flatten()\n",
    "        sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3).flatten()\n",
    "        \n",
    "        # Combine all features\n",
    "        feature_vector = np.hstack([hog_feature, lbp_feature, canny_edges, sobel_x, sobel_y])\n",
    "        features.append(feature_vector)\n",
    "    return np.array(features)\n",
    "\n",
    "dataset_path = \"Face-Mask-Detection/dataset\"\n",
    "X, y = load_images(dataset_path)\n",
    "X_features = extract_features(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_features = scaler.fit_transform(X_features)\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X_features)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in skf.split(X_pca, y):\n",
    "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm = GridSearchCV(SVC(), param_grid_svm, cv=3)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.best_estimator_.predict(X_test)\n",
    "\n",
    "param_grid_mlp = {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'activation': ['relu', 'tanh'], 'max_iter': [300, 500]}\n",
    "mlp = GridSearchCV(MLPClassifier(), param_grid_mlp, cv=3)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Best SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Best MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"\\nSVM Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nMLP Report:\\n\", classification_report(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fe143",
   "metadata": {},
   "source": [
    "Task B : Face Mask Detection Using Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6718b6ec-22be-43e8-96b0-de10056b05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN with optimizer=adam, dropout=0.3, learning_rate=0.001\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5612 - loss: 0.6744 - val_accuracy: 0.7730 - val_loss: 0.4775 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.7973 - loss: 0.4245 - val_accuracy: 0.8736 - val_loss: 0.3359 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8674 - loss: 0.3106 - val_accuracy: 0.9141 - val_loss: 0.2240 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9077 - loss: 0.2166 - val_accuracy: 0.8994 - val_loss: 0.2375 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9236 - loss: 0.1804 - val_accuracy: 0.9252 - val_loss: 0.1889 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9398 - loss: 0.1447 - val_accuracy: 0.9141 - val_loss: 0.2101 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9512 - loss: 0.1263 - val_accuracy: 0.9104 - val_loss: 0.2484 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9486 - loss: 0.1341 - val_accuracy: 0.9423 - val_loss: 0.1762 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9756 - loss: 0.0715 - val_accuracy: 0.9497 - val_loss: 0.1733 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9805 - loss: 0.0545 - val_accuracy: 0.9399 - val_loss: 0.1738 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9876 - loss: 0.0460 - val_accuracy: 0.9276 - val_loss: 0.2455 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9914 - loss: 0.0284 - val_accuracy: 0.9485 - val_loss: 0.2042 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9969 - loss: 0.0143 - val_accuracy: 0.9558 - val_loss: 0.1934 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9995 - loss: 0.0088 - val_accuracy: 0.9595 - val_loss: 0.1944 - learning_rate: 2.0000e-04\n",
      "Training CNN with optimizer=adam, dropout=0.3, learning_rate=0.0001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5794 - loss: 0.6793 - val_accuracy: 0.7178 - val_loss: 0.5978 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.7142 - loss: 0.5629 - val_accuracy: 0.7926 - val_loss: 0.4747 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8031 - loss: 0.4442 - val_accuracy: 0.8479 - val_loss: 0.3904 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8319 - loss: 0.3903 - val_accuracy: 0.8687 - val_loss: 0.3390 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8618 - loss: 0.3404 - val_accuracy: 0.8798 - val_loss: 0.3128 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8726 - loss: 0.3040 - val_accuracy: 0.8883 - val_loss: 0.2861 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8937 - loss: 0.2646 - val_accuracy: 0.8969 - val_loss: 0.2607 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8970 - loss: 0.2487 - val_accuracy: 0.8883 - val_loss: 0.2586 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9073 - loss: 0.2331 - val_accuracy: 0.9104 - val_loss: 0.2457 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9153 - loss: 0.2252 - val_accuracy: 0.9215 - val_loss: 0.2166 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9206 - loss: 0.2097 - val_accuracy: 0.9239 - val_loss: 0.2125 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9213 - loss: 0.1963 - val_accuracy: 0.9301 - val_loss: 0.2025 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9309 - loss: 0.1800 - val_accuracy: 0.9276 - val_loss: 0.1962 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9365 - loss: 0.1754 - val_accuracy: 0.9374 - val_loss: 0.1848 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9451 - loss: 0.1472 - val_accuracy: 0.9227 - val_loss: 0.1924 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9503 - loss: 0.1328 - val_accuracy: 0.9313 - val_loss: 0.1884 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9514 - loss: 0.1322 - val_accuracy: 0.9313 - val_loss: 0.1751 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9496 - loss: 0.1269 - val_accuracy: 0.9472 - val_loss: 0.1632 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9553 - loss: 0.1208 - val_accuracy: 0.9472 - val_loss: 0.1672 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9606 - loss: 0.1066 - val_accuracy: 0.9460 - val_loss: 0.1615 - learning_rate: 1.0000e-04\n",
      "Training CNN with optimizer=adam, dropout=0.5, learning_rate=0.001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.5969 - loss: 0.6548 - val_accuracy: 0.8012 - val_loss: 0.4351 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.8166 - loss: 0.4188 - val_accuracy: 0.8577 - val_loss: 0.3591 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8552 - loss: 0.3340 - val_accuracy: 0.9006 - val_loss: 0.2439 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9039 - loss: 0.2256 - val_accuracy: 0.9031 - val_loss: 0.2231 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9148 - loss: 0.2028 - val_accuracy: 0.9117 - val_loss: 0.2026 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9397 - loss: 0.1514 - val_accuracy: 0.9276 - val_loss: 0.1825 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9488 - loss: 0.1292 - val_accuracy: 0.9460 - val_loss: 0.1491 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9613 - loss: 0.1055 - val_accuracy: 0.9387 - val_loss: 0.1513 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.9730 - loss: 0.0787 - val_accuracy: 0.9436 - val_loss: 0.1500 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9730 - loss: 0.0745 - val_accuracy: 0.9374 - val_loss: 0.1760 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9861 - loss: 0.0410 - val_accuracy: 0.9448 - val_loss: 0.1623 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9932 - loss: 0.0263 - val_accuracy: 0.9521 - val_loss: 0.1748 - learning_rate: 2.0000e-04\n",
      "Training CNN with optimizer=adam, dropout=0.5, learning_rate=0.0001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - accuracy: 0.5643 - loss: 0.6825 - val_accuracy: 0.6589 - val_loss: 0.6233 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6933 - loss: 0.5948 - val_accuracy: 0.7485 - val_loss: 0.5169 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.7602 - loss: 0.4969 - val_accuracy: 0.8000 - val_loss: 0.4517 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8092 - loss: 0.4353 - val_accuracy: 0.8405 - val_loss: 0.3958 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8256 - loss: 0.3973 - val_accuracy: 0.8650 - val_loss: 0.3526 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.8383 - loss: 0.3638 - val_accuracy: 0.8687 - val_loss: 0.3292 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8602 - loss: 0.3208 - val_accuracy: 0.8847 - val_loss: 0.3030 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.8795 - loss: 0.2947 - val_accuracy: 0.8638 - val_loss: 0.3026 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8798 - loss: 0.2822 - val_accuracy: 0.8982 - val_loss: 0.2677 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.8958 - loss: 0.2664 - val_accuracy: 0.9031 - val_loss: 0.2470 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9040 - loss: 0.2447 - val_accuracy: 0.8957 - val_loss: 0.2517 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9122 - loss: 0.2230 - val_accuracy: 0.9104 - val_loss: 0.2302 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9252 - loss: 0.2025 - val_accuracy: 0.9031 - val_loss: 0.2382 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9153 - loss: 0.1989 - val_accuracy: 0.9215 - val_loss: 0.2052 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.9353 - loss: 0.1702 - val_accuracy: 0.9276 - val_loss: 0.1950 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9304 - loss: 0.1776 - val_accuracy: 0.9141 - val_loss: 0.2172 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9389 - loss: 0.1603 - val_accuracy: 0.9374 - val_loss: 0.1848 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9469 - loss: 0.1530 - val_accuracy: 0.9276 - val_loss: 0.1886 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9424 - loss: 0.1544 - val_accuracy: 0.9337 - val_loss: 0.1784 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9535 - loss: 0.1279 - val_accuracy: 0.9460 - val_loss: 0.1670 - learning_rate: 1.0000e-04\n",
      "Training CNN with optimizer=sgd, dropout=0.3, learning_rate=0.001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4865 - loss: 0.6940 - val_accuracy: 0.5288 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4955 - loss: 0.6926 - val_accuracy: 0.5325 - val_loss: 0.6911 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5364 - loss: 0.6916 - val_accuracy: 0.5448 - val_loss: 0.6899 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5380 - loss: 0.6906 - val_accuracy: 0.5460 - val_loss: 0.6890 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5514 - loss: 0.6890 - val_accuracy: 0.5521 - val_loss: 0.6881 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5429 - loss: 0.6886 - val_accuracy: 0.5558 - val_loss: 0.6873 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5793 - loss: 0.6878 - val_accuracy: 0.5583 - val_loss: 0.6864 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5456 - loss: 0.6881 - val_accuracy: 0.5521 - val_loss: 0.6855 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5648 - loss: 0.6873 - val_accuracy: 0.5693 - val_loss: 0.6852 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5805 - loss: 0.6856 - val_accuracy: 0.5742 - val_loss: 0.6846 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5782 - loss: 0.6853 - val_accuracy: 0.5840 - val_loss: 0.6839 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5746 - loss: 0.6848 - val_accuracy: 0.5988 - val_loss: 0.6832 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5885 - loss: 0.6839 - val_accuracy: 0.5828 - val_loss: 0.6823 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5667 - loss: 0.6835 - val_accuracy: 0.5926 - val_loss: 0.6817 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5735 - loss: 0.6825 - val_accuracy: 0.6025 - val_loss: 0.6811 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.6021 - loss: 0.6792 - val_accuracy: 0.6049 - val_loss: 0.6803 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5949 - loss: 0.6806 - val_accuracy: 0.6147 - val_loss: 0.6796 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5947 - loss: 0.6797 - val_accuracy: 0.6160 - val_loss: 0.6788 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6013 - loss: 0.6798 - val_accuracy: 0.6098 - val_loss: 0.6776 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5870 - loss: 0.6773 - val_accuracy: 0.6172 - val_loss: 0.6769 - learning_rate: 0.0010\n",
      "Training CNN with optimizer=sgd, dropout=0.3, learning_rate=0.0001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5038 - loss: 0.6929 - val_accuracy: 0.5448 - val_loss: 0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4851 - loss: 0.6933 - val_accuracy: 0.5423 - val_loss: 0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5236 - loss: 0.6926 - val_accuracy: 0.5411 - val_loss: 0.6926 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5145 - loss: 0.6931 - val_accuracy: 0.5472 - val_loss: 0.6925 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5492 - loss: 0.6922 - val_accuracy: 0.5497 - val_loss: 0.6924 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5161 - loss: 0.6927 - val_accuracy: 0.5558 - val_loss: 0.6924 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5095 - loss: 0.6928 - val_accuracy: 0.5571 - val_loss: 0.6923 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5071 - loss: 0.6932 - val_accuracy: 0.5583 - val_loss: 0.6923 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5167 - loss: 0.6929 - val_accuracy: 0.5595 - val_loss: 0.6922 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5206 - loss: 0.6926 - val_accuracy: 0.5607 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5276 - loss: 0.6920 - val_accuracy: 0.5620 - val_loss: 0.6921 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5299 - loss: 0.6921 - val_accuracy: 0.5644 - val_loss: 0.6920 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5143 - loss: 0.6927 - val_accuracy: 0.5644 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5295 - loss: 0.6926 - val_accuracy: 0.5632 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5464 - loss: 0.6919 - val_accuracy: 0.5607 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5161 - loss: 0.6925 - val_accuracy: 0.5607 - val_loss: 0.6918 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5196 - loss: 0.6926 - val_accuracy: 0.5632 - val_loss: 0.6917 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5235 - loss: 0.6925 - val_accuracy: 0.5595 - val_loss: 0.6917 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5236 - loss: 0.6924 - val_accuracy: 0.5583 - val_loss: 0.6916 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4969 - loss: 0.6929 - val_accuracy: 0.5583 - val_loss: 0.6916 - learning_rate: 1.0000e-04\n",
      "Training CNN with optimizer=sgd, dropout=0.5, learning_rate=0.001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.4965 - loss: 0.6951 - val_accuracy: 0.4491 - val_loss: 0.6943 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4873 - loss: 0.6943 - val_accuracy: 0.5117 - val_loss: 0.6925 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5139 - loss: 0.6923 - val_accuracy: 0.5791 - val_loss: 0.6912 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5446 - loss: 0.6909 - val_accuracy: 0.6123 - val_loss: 0.6901 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5337 - loss: 0.6903 - val_accuracy: 0.6245 - val_loss: 0.6890 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5434 - loss: 0.6894 - val_accuracy: 0.6331 - val_loss: 0.6882 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5413 - loss: 0.6900 - val_accuracy: 0.6454 - val_loss: 0.6872 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5683 - loss: 0.6885 - val_accuracy: 0.6528 - val_loss: 0.6863 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5809 - loss: 0.6865 - val_accuracy: 0.6638 - val_loss: 0.6855 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.6002 - loss: 0.6852 - val_accuracy: 0.6613 - val_loss: 0.6846 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5912 - loss: 0.6856 - val_accuracy: 0.6663 - val_loss: 0.6838 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5853 - loss: 0.6842 - val_accuracy: 0.6650 - val_loss: 0.6830 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5789 - loss: 0.6845 - val_accuracy: 0.6601 - val_loss: 0.6821 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6003 - loss: 0.6816 - val_accuracy: 0.6601 - val_loss: 0.6816 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6241 - loss: 0.6800 - val_accuracy: 0.6638 - val_loss: 0.6806 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6098 - loss: 0.6806 - val_accuracy: 0.6589 - val_loss: 0.6797 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.6042 - loss: 0.6799 - val_accuracy: 0.6638 - val_loss: 0.6784 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5985 - loss: 0.6791 - val_accuracy: 0.6663 - val_loss: 0.6779 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6054 - loss: 0.6792 - val_accuracy: 0.6712 - val_loss: 0.6773 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.6111 - loss: 0.6777 - val_accuracy: 0.6712 - val_loss: 0.6761 - learning_rate: 0.0010\n",
      "Training CNN with optimizer=sgd, dropout=0.5, learning_rate=0.0001\n",
      "Epoch 1/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4776 - loss: 0.6982 - val_accuracy: 0.4442 - val_loss: 0.7018 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4907 - loss: 0.6960 - val_accuracy: 0.4442 - val_loss: 0.7011 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4868 - loss: 0.6971 - val_accuracy: 0.4442 - val_loss: 0.7005 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4924 - loss: 0.6956 - val_accuracy: 0.4442 - val_loss: 0.6999 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4798 - loss: 0.6985 - val_accuracy: 0.4442 - val_loss: 0.6993 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4767 - loss: 0.6969 - val_accuracy: 0.4442 - val_loss: 0.6988 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4790 - loss: 0.6959 - val_accuracy: 0.4454 - val_loss: 0.6983 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4740 - loss: 0.6966 - val_accuracy: 0.4454 - val_loss: 0.6978 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4670 - loss: 0.6985 - val_accuracy: 0.4454 - val_loss: 0.6974 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4925 - loss: 0.6949 - val_accuracy: 0.4454 - val_loss: 0.6969 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4900 - loss: 0.6944 - val_accuracy: 0.4454 - val_loss: 0.6965 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4897 - loss: 0.6947 - val_accuracy: 0.4454 - val_loss: 0.6961 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.4742 - loss: 0.6948 - val_accuracy: 0.4515 - val_loss: 0.6958 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.4821 - loss: 0.6945 - val_accuracy: 0.4540 - val_loss: 0.6954 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5043 - loss: 0.6915 - val_accuracy: 0.4564 - val_loss: 0.6951 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5073 - loss: 0.6931 - val_accuracy: 0.4552 - val_loss: 0.6947 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5047 - loss: 0.6942 - val_accuracy: 0.4577 - val_loss: 0.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5049 - loss: 0.6942 - val_accuracy: 0.4589 - val_loss: 0.6941 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5072 - loss: 0.6929 - val_accuracy: 0.4650 - val_loss: 0.6939 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5157 - loss: 0.6930 - val_accuracy: 0.4601 - val_loss: 0.6936 - learning_rate: 1.0000e-04\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9386 - loss: 0.2029\n",
      "CNN (Optimizer=adam, Dropout=0.3, Learning Rate=0.001) Accuracy: 0.9497\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9401 - loss: 0.1774\n",
      "CNN (Optimizer=adam, Dropout=0.3, Learning Rate=0.0001) Accuracy: 0.9460\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9391 - loss: 0.1655\n",
      "CNN (Optimizer=adam, Dropout=0.5, Learning Rate=0.001) Accuracy: 0.9460\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9425 - loss: 0.1720\n",
      "CNN (Optimizer=adam, Dropout=0.5, Learning Rate=0.0001) Accuracy: 0.9460\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5873 - loss: 0.6802\n",
      "CNN (Optimizer=sgd, Dropout=0.3, Learning Rate=0.001) Accuracy: 0.6172\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5540 - loss: 0.6917\n",
      "CNN (Optimizer=sgd, Dropout=0.3, Learning Rate=0.0001) Accuracy: 0.5583\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6336 - loss: 0.6797\n",
      "CNN (Optimizer=sgd, Dropout=0.5, Learning Rate=0.001) Accuracy: 0.6712\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4535 - loss: 0.6941\n",
      "CNN (Optimizer=sgd, Dropout=0.5, Learning Rate=0.0001) Accuracy: 0.4601\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_images(folder):\n",
    "    images, labels = [], []\n",
    "    for category in [\"with_mask\", \"without_mask\"]:\n",
    "        path = os.path.join(folder, category)\n",
    "        label = 1 if category == \"with_mask\" else 0\n",
    "        for file in os.listdir(path):\n",
    "            img_path = os.path.join(path, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (64, 64))\n",
    "                img = cv2.equalizeHist(img)  # Apply Histogram Equalization\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def build_cnn(optimizer='adam', dropout_rate=0.5, learning_rate=1e-3):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer! Choose 'adam' or 'sgd'.\")\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"Face-Mask-Detection/dataset\"\n",
    "X, y = load_images(dataset_path)\n",
    "X = X.reshape(-1, 64, 64, 1) / 255.0  # Normalize and reshape\n",
    "xTrainCNN, xTestCNN, yTrainCNN, yTestCNN = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter variations\n",
    "optimizers = ['adam', 'sgd']\n",
    "dropoutValues = [0.3, 0.5]\n",
    "learningRates = [1e-3, 1e-4]\n",
    "\n",
    "for opt in optimizers:\n",
    "    for dropout in dropoutValues:\n",
    "        for learning in learningRates:\n",
    "            print(f\"Training CNN with optimizer={opt}, dropout={dropout}, learning_rate={learning}\")\n",
    "            model = build_cnn(optimizer=opt, dropout_rate=dropout, learning_rate=learning)\n",
    "            \n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-5)\n",
    "            ]\n",
    "            \n",
    "            model.fit(xTrainCNN, yTrainCNN, validation_data=(xTestCNN, yTestCNN), epochs=20, callbacks=callbacks, verbose=1)\n",
    "            model.save(f'face_mask_classifier_{opt}_{dropout}_{learning}.keras')\n",
    "\n",
    "# Evaluate Models\n",
    "for opt in optimizers:\n",
    "    for dropout in dropoutValues:\n",
    "        for learning in learningRates:\n",
    "            model = tf.keras.models.load_model(f'face_mask_classifier_{opt}_{dropout}_{learning}.keras')\n",
    "            testLoss, testAccuracy = model.evaluate(xTestCNN, yTestCNN)\n",
    "            print(f\"CNN (Optimizer={opt}, Dropout={dropout}, Learning Rate={learning}) Accuracy: {testAccuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
